{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31e77d9-338b-4028-9fd3-7b7d3173fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f7eb900-42db-4c4b-976c-2ed1655d1d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting: 202412-citibike-tripdata_1.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   ride_id             1000000 non-null  object \n",
      " 1   rideable_type       1000000 non-null  object \n",
      " 2   started_at          1000000 non-null  object \n",
      " 3   ended_at            1000000 non-null  object \n",
      " 4   start_station_name  999375 non-null   object \n",
      " 5   start_station_id    999375 non-null   object \n",
      " 6   end_station_name    996417 non-null   object \n",
      " 7   end_station_id      995525 non-null   object \n",
      " 8   start_lat           1000000 non-null  float64\n",
      " 9   start_lng           1000000 non-null  float64\n",
      " 10  end_lat             999795 non-null   float64\n",
      " 11  end_lng             999795 non-null   float64\n",
      " 12  member_casual       1000000 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 99.2+ MB\n",
      "None\n",
      "            ride_id  rideable_type               started_at   \n",
      "0  B44E5B10AEE58AD0   classic_bike  2024-12-14 10:58:18.153  \\\n",
      "1  BC252DC6A6011556  electric_bike  2024-12-12 14:46:12.473   \n",
      "2  6FBE55EF6FE8736D  electric_bike  2024-12-11 07:55:18.770   \n",
      "3  908890DE7FDCF9FE  electric_bike  2024-12-09 22:51:11.668   \n",
      "4  D5D366379A4DC0A8   classic_bike  2024-12-10 18:48:40.063   \n",
      "\n",
      "                  ended_at                  start_station_name   \n",
      "0  2024-12-14 11:11:11.308  Frederick Douglass Blvd & W 145 St  \\\n",
      "1  2024-12-12 16:45:37.777               Madison Ave & E 99 St   \n",
      "2  2024-12-11 08:02:23.460               Columbia St & Kane St   \n",
      "3  2024-12-09 22:57:43.495                     E 13 St & 2 Ave   \n",
      "4  2024-12-10 19:10:32.264                    11 Ave & W 41 St   \n",
      "\n",
      "  start_station_id  end_station_name end_station_id  start_lat  start_lng   \n",
      "0          7954.12  E 138 St & 5 Ave        7809.13  40.823061 -73.941928  \\\n",
      "1          7443.01               NaN            NaN  40.789485 -73.952429   \n",
      "2          4422.05               NaN            NaN  40.687632 -74.001626   \n",
      "3          5820.08   E 10 St & 2 Ave        5746.02  40.731539 -73.985302   \n",
      "4          6726.01   E 25 St & 1 Ave        6004.07  40.760301 -73.998842   \n",
      "\n",
      "     end_lat    end_lng member_casual  \n",
      "0  40.814490 -73.936153        member  \n",
      "1  40.780000 -73.960000        member  \n",
      "2  40.690000 -74.000000        member  \n",
      "3  40.729708 -73.986598        member  \n",
      "4  40.738177 -73.977387        member  \n"
     ]
    }
   ],
   "source": [
    "# Examine each zip file to ensure columns/data match\n",
    "\n",
    "# Path to the each ZIP file\n",
    "zip_path = \"Resources/202412-citibike-tripdata.zip\"\n",
    "\n",
    "# Open the ZIP file and read its first CSV\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    csv_filename = z.namelist()[0]  # Get the first file inside the ZIP\n",
    "    print(f\"Extracting: {csv_filename}\")  # Show the file name inside the ZIP\n",
    "    with z.open(csv_filename) as f:\n",
    "        df = pd.read_csv(f,low_memory=False)  # Load CSV into DataFrame\n",
    "\n",
    "# Display basic info about the DataFrame\n",
    "print(df.info())  # Shows column names, data types, and missing values\n",
    "print(df.head())  # Shows first 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0f4872-eb5e-45a6-bf86-ca1c5c5371fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id               1000000\n",
       "rideable_type               2\n",
       "started_at             999269\n",
       "ended_at               999235\n",
       "start_station_name       2137\n",
       "start_station_id         2138\n",
       "end_station_name         2129\n",
       "end_station_id           2148\n",
       "start_lat                2160\n",
       "start_lng                2153\n",
       "end_lat                  2144\n",
       "end_lng                  2135\n",
       "member_casual               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dbb96c9-7d22-40d2-a886-f51b1e33c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 202412-citibike-tripdata_1.csv\n",
      "Processing file: 202412-citibike-tripdata_3.csv\n",
      "Processing file: 202412-citibike-tripdata_2.csv\n",
      "Processing file: 202501-citibike-tripdata_1.csv\n",
      "Processing file: 202501-citibike-tripdata_3.csv\n",
      "Processing file: 202501-citibike-tripdata_2.csv\n",
      "Processing file: 202411-citibike-tripdata_3.csv\n",
      "Processing file: 202411-citibike-tripdata_2.csv\n",
      "Processing file: 202411-citibike-tripdata_1.csv\n",
      "Processing file: 202411-citibike-tripdata_4.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8145780 entries, 0 to 8145779\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 807.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get all ZIP files in the directory\n",
    "zip_files = glob.glob(\"Resources/*.zip\")\n",
    "\n",
    "# Define chunk size (adjust based on RAM capacity)\n",
    "chunk_size = 100_000  # Process 100,000 rows at a time\n",
    "\n",
    "# Placeholder for merged DataFrame (use a list to store processed chunks)\n",
    "dfs = []\n",
    "\n",
    "# Iterate over each ZIP file\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(zip_file, 'r') as z:\n",
    "        # Iterate over all CSV files inside the ZIP\n",
    "        for csv_filename in z.namelist():\n",
    "            if csv_filename.endswith('.csv'):  # Check if it's a CSV file\n",
    "                print(f\"Processing file: {csv_filename}\")  # Show the current file being processed\n",
    "                \n",
    "                # Open the CSV file inside the ZIP and read it in chunks\n",
    "                with z.open(csv_filename) as f:\n",
    "                    for chunk in pd.read_csv(f, chunksize=chunk_size, low_memory=False):\n",
    "                        chunk.drop_duplicates(inplace=True)\n",
    "                        chunk.dropna()\n",
    "                        dfs.append(chunk)\n",
    "\n",
    "# Merge all chunks into one final DataFrame\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display basic information about the final DataFrame\n",
    "print(df_final.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754561cb-ce49-484e-ad52-344e8040f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df_final.to_csv(\"Output/citybike_cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f9218-d859-4192-8d29-535e16e7a2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
